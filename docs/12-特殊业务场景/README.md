# 12. 特殊业务场景处理

## 12.1 概述

本章节将重点分析电商平台中几种特殊且具有挑战性的业务场景的实现方案，包括秒杀系统的高并发处理、大数据量报表的生成、搜索功能的实现以及推荐系统的构建。这些场景往往是标准业务流程的延伸，但对系统的性能、稳定性和算法能力提出了更高的要求。

## 12.2 秒杀与高并发处理

秒杀活动的特点是瞬时并发量极高，流量集中，直接对库存和下单流程造成巨大冲击。为此，系统设计了一套独立于普通购物流程之外的秒杀解决方案。

### 12.2.1 秒杀系统架构

```mermaid
graph TD
    subgraph Browser[浏览器]
        A[静态秒杀页面] --> B{秒杀按钮}
    end
    
    subgraph SLB[负载均衡]
        Nginx
    end

    subgraph GW[API网关]
        RateLimiter[限流]
    end

    subgraph Service[服务层]
        C[秒杀服务] --> D[下单服务]
    end

    subgraph Cache[缓存层]
        E[Redis库存]
        F[秒杀令牌桶]
        G[用户限购标识]
    end

    subgraph MQ[消息队列]
        H[RocketMQ]
    end

    subgraph DB[数据库]
        I[订单表]
    end

    B --> |1. 获取秒杀令牌| GW
    GW --> |2. 限流| C
    C --> |3. 校验用户/令牌| F & G
    F & G --> |4. 校验通过| C
    C --> |5. Redis预减库存| E
    E --> |6. 减库存成功| C
    C --> |7. 发送下单消息| H
    C --> |8. 返回"排队中"| Browser
    D --.-> |9. 消费消息| H
    D --> |10. 创建订单| I
```

### 12.2.2 核心优化策略

1.  **动静分离**: 秒杀页面完全静态化，并部署到CDN，最大限度减轻Web服务器压力。
2.  **流量削峰**:
    -   **前端控制**: 秒杀开始前，按钮置灰。用户点击后，按钮也置灰一段时间，防止重复提交。
    -   **API网关限流**: 在网关层针对秒杀接口设置极高的限流阈值，拦截大部分无效请求。
    -   **令牌桶机制**: 点击秒杀按钮后，后端会先发放一个有时效的令牌。只有携带有效令牌的请求才能进入后续流程，令牌桶的大小即为商品库存的N倍（如2倍），有效控制进入核心逻辑的流量。
3.  **读操作优化**:
    -   商品信息、秒杀详情等数据全部预热到Redis中，所有读请求均由缓存服务。
4.  **写操作优化**:
    -   **Redis预减库存**: 库存的扣减操作完全在Redis中完成，利用其原子性保证并发正确性，避免直接操作数据库。
    -   **异步下单**: Redis减库存成功后，并不立即创建订单，而是发送一条包含用户ID和商品ID的消息到RocketMQ。由后端的下单服务异步消费消息，慢慢地将订单写入数据库。
    -   **内存标记**: 在秒杀服务中使用`ConcurrentHashMap`或Redis的Set来标记已经抢购过的用户，防止用户重复下单。

## 12.3 大数据量报表处理

运营后台需要生成各种维度的统计报表，如每日销售额、热门商品排行等。当数据量巨大时，实时查询会导致数据库压力过大甚至超时。

### 12.3.1 解决方案

采用**离线计算** + **预生成**的策略。

1.  **数据同步**: 使用`Canal`等工具实时监听MySQL的binlog，将订单、支付等业务数据同步到一个专门用于数据分析的`Elasticsearch`集群或数据仓库（如ClickHouse, Doris）中。
2.  **定时任务**: 使用`XXL-Job`或`Spring Task`等调度框架，在每日凌晨等业务低峰期，触发一个批处理任务。
3.  **离线计算**: 批处理任务从Elasticsearch或数据仓库中拉取前一天的数据，进行复杂的聚合、统计和分析。
4.  **结果回写**: 将计算好的报表结果（如一个包含各种统计指标的JSON对象）回写到MySQL的一个专门的报表结果表中，或直接写入Redis。
5.  **前端查询**: 运营人员在后台查询报表时，系统直接从报表结果表或Redis中读取已经生成好的数据，实现秒级响应。

## 12.4 搜索功能实现

为了提供强大的全文搜索能力，项目引入了Elasticsearch。

### 12.4.1 架构与流程

1.  **数据同步**: 与报表类似，使用`Canal` + `RocketMQ` 的组合，将商品服务中`item`表的变化（新增、更新、删除）实时同步到MQ。
2.  **索引构建服务**: 创建一个专门的`search-service`，消费MQ中的消息，并调用Elasticsearch的API来对商品信息的索引进行相应的增、删、改操作。
3.  **分词与映射 (Mapping)**:
    -   在Elasticsearch中为商品索引定义精细的Mapping。
    -   对商品标题、描述等字段使用IK分词器（`ik_max_word`模式）以提高中文分词的准确率和召回率。
    -   对品牌、分类等字段使用`keyword`类型，用于精确匹配和聚合分析。
4.  **搜索接口**:
    -   前端的搜索请求会调用`search-service`提供的搜索接口。
    -   后端使用Elasticsearch的`bool`查询组合多个查询条件（如关键词匹配、品牌过滤、价格区间筛选）。
    -   利用Elasticsearch的聚合（Aggregations）功能，可以方便地实现"品牌"、"分类"等过滤条件的统计。
    -   支持按相关度、价格、销量等多种方式进行排序。

## 12.5 推荐系统实现

项目初期采用基于规则和热门度的简单推荐，未来可以演进为基于协同过滤的个性化推荐。

### 12.5.1 初期方案：基于热门度和规则

-   **热门推荐**:
    -   使用定时任务，统计一段时间内商品的销量、点击量、加购量。
    -   将这些数据加权计算出一个"热度分"，存储在Redis的Sorted Set中。
    -   首页或商品详情页的热门推荐，直接从Sorted Set中获取Top N的商品。
-   **规则推荐 ("看了又看")**:
    -   根据用户当前浏览的商品，推荐同一分类、同一品牌下的其他热门商品。

### 12.5.2 进阶方案：基于协同过滤的个性化推荐

1.  **用户行为数据收集**: 收集用户的"点击"、"加购"、"购买"、"收藏"等行为日志，发送到大数据平台（如Hadoop/Spark）。
2.  **离线模型训练**:
    -   使用Spark MLlib等机器学习库，基于用户行为数据，离线训练一个协同过滤模型（如ALS算法）。
    -   模型会计算出"物品相似度矩阵"（Item-CF）或"用户相似度矩阵"（User-CF）。
    -   将计算好的推荐结果（如为每个用户推荐Top 100个商品）存储到Redis或HBase中。
3.  **在线推荐**:
    -   用户访问推荐页面时，推荐服务直接从Redis中拉取已经计算好的推荐列表。
    -   对于新用户或行为较少的老用户，可以降级为热门推荐。

## 12.6 总结

针对不同的特殊业务场景，需要采用专门的技术方案来应对其挑战。核心思想是**隔离**、**异步**、**预计算**和**引入专用中间件**。通过将这些复杂场景与主业务流程解耦，可以在不影响核心功能稳定性的前提下，实现强大的扩展功能。 